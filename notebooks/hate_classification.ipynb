{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, pipeline\n",
    "from scipy.special import softmax\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102558, 14) (102558, 14)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/processed/sp_elected_state_deputies_tweets.csv\"\n",
    "raw_df = pd.read_csv(file_path, on_bad_lines=\"skip\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "duplicated_indexes = raw_df[raw_df.duplicated()].index\n",
    "df = raw_df.drop(duplicated_indexes)\n",
    "\n",
    "print(raw_df.shape, df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFENSE_MODELS = {\n",
    "    \"rc_bert_base\": \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "    \"rc_mdeberta_base\": \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "    \"cl_distilbert_base\": \"citizenlab/distilbert-base-multilingual-cased-toxicity\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                     | 10/2052 [00:04<11:51,  2.87it/s]/home/paim/projects/projeto-tera/venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2052/2052 [13:18<00:00,  2.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2052/2052 [28:35<00:00,  1.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2052/2052 [08:27<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "col_name = \"content\"\n",
    "batch_size = 50\n",
    "num_batches = len(df) // batch_size + 1\n",
    "results = {}\n",
    "\n",
    "for model_key, model_name in OFFENSE_MODELS.items():\n",
    "    if device.type == \"cuda\":\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_name, device=0)\n",
    "    else:\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "\n",
    "    results[model_key] = []\n",
    "    for i in tqdm(range(num_batches)):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min((i + 1) * batch_size, len(df))\n",
    "        batch_texts = df[col_name][batch_start:batch_end].tolist()\n",
    "        batch_results = classifier(batch_texts)\n",
    "        results[model_key] += batch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_bert_base\n",
      "rc_mdeberta_base\n",
      "cl_distilbert_base\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102558 entries, 0 to 102557\n",
      "Data columns (total 20 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   url                       102558 non-null  object \n",
      " 1   date                      102558 non-null  object \n",
      " 2   content                   102558 non-null  object \n",
      " 3   user                      102558 non-null  object \n",
      " 4   reply_count               102558 non-null  int64  \n",
      " 5   retweet_count             102558 non-null  int64  \n",
      " 6   like_count                102558 non-null  int64  \n",
      " 7   quote_count               102558 non-null  int64  \n",
      " 8   in_reply_to_id            94389 non-null   float64\n",
      " 9   in_reply_to_user          94122 non-null   object \n",
      " 10  conversation_id           102558 non-null  object \n",
      " 11  conversation_user         102558 non-null  object \n",
      " 12  class_label               102558 non-null  bool   \n",
      " 13  class_score               102558 non-null  float64\n",
      " 14  rc_bert_base_label        102558 non-null  bool   \n",
      " 15  rc_bert_base_score        102558 non-null  float64\n",
      " 16  rc_mdeberta_base_label    102558 non-null  bool   \n",
      " 17  rc_mdeberta_base_score    102558 non-null  float64\n",
      " 18  cl_distilbert_base_label  102558 non-null  object \n",
      " 19  cl_distilbert_base_score  102558 non-null  float64\n",
      "dtypes: bool(3), float64(5), int64(4), object(8)\n",
      "memory usage: 13.6+ MB\n"
     ]
    }
   ],
   "source": [
    "for key in OFFENSE_MODELS.keys():\n",
    "    print(key)\n",
    "    df[f'{key}_label'] = [result[\"label\"] for result in results[key]]\n",
    "    df[f'{key}_score'] = [result[\"score\"] for result in results[key]]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rc_bert_base_label  rc_mdeberta_base_label  cl_distilbert_base_label\n",
       "False               False                   False                       69168\n",
       "True                True                    False                       17416\n",
       "False               True                    False                        7253\n",
       "True                False                   False                        4557\n",
       "                    True                    True                         2006\n",
       "False               False                   True                         1597\n",
       "                    True                    True                          378\n",
       "True                False                   True                          183\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['content', 'rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].value_counts()\n",
    "df[['rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rc_bert_base_label</th>\n",
       "      <th>rc_mdeberta_base_label</th>\n",
       "      <th>cl_distilbert_base_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102558</td>\n",
       "      <td>102558</td>\n",
       "      <td>102558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>78396</td>\n",
       "      <td>75505</td>\n",
       "      <td>98394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rc_bert_base_label rc_mdeberta_base_label cl_distilbert_base_label\n",
       "count              102558                 102558                   102558\n",
       "unique                  2                      2                        2\n",
       "top                 False                  False                    False\n",
       "freq                78396                  75505                    98394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/processed/\"\n",
    "output_file = f\"classified.csv\"\n",
    "\n",
    "# Para salvar os dados, descomente as linhas abaixo\n",
    "df.to_csv(f\"{output_path}{output_file}\", sep=\";\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Classification head function\n",
    "def get_class(logit):\n",
    "    scores = softmax(logit)\n",
    "    label = config.id2label[np.argmax(scores)]\n",
    "    # print(f\"get_class(): {logit=}, {scores=}, {label=}\")\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_gpu(batch):\n",
    "    model_input = tokenizer(\n",
    "        *(list(batch[\"rawContent\"]),), padding=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**model_input)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "    return logits\n",
    "\n",
    "\n",
    "def process_batch_cpu(batch):\n",
    "    model_input = tokenizer(\n",
    "        *(list(batch[\"rawContent\"]),), padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**model_input)\n",
    "        logits = outputs.logits.detach().numpy()\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\":  # GPU\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "    process_batch = process_batch_gpu\n",
    "\n",
    "else:  # CPU\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    process_batch = process_batch_cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[i : \u001b[38;5;28mlen\u001b[39m(df)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 11\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m logits_list\u001b[38;5;241m.\u001b[39mappend(logits)\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mprocess_batch_gpu\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_input)\n\u001b[0;32m----> 8\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 50\n",
    "logits_list = []\n",
    "\n",
    "# for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "for i in range(0, len(df), BATCH_SIZE):\n",
    "    if i + BATCH_SIZE < len(df):\n",
    "        batch = df.iloc[i : i + BATCH_SIZE].copy()\n",
    "    else:\n",
    "        batch = df.iloc[i : len(df)].copy()\n",
    "\n",
    "    logits = process_batch(batch)\n",
    "    logits_list.append(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.concatenate(logits_list)\n",
    "logits.shape\n",
    "\n",
    "classes = []\n",
    "for logit in logits:\n",
    "    classes.append(get_class(logit))\n",
    "\n",
    "df[\"BertL-offense\"] = classes\n",
    "df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_df = df[df[\"BertL-offense\"] == True]\n",
    "print(offensive_df.shape)\n",
    "offensive_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_df[\"rawContent\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/processed/\"\n",
    "output_file = f\"erika_bert-large-portuguese-cased-hatebr_output.csv\"\n",
    "\n",
    "# Para salvar os dados, descomente as linhas abaixo\n",
    "# df.to_csv(f\"{output_path}{output_file}\", sep=\";\", encoding=\"utf-8\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
