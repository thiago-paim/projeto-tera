{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from scipy.special import softmax\n",
    "\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_df.shape=(215622, 13)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215622 entries, 0 to 215621\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype              \n",
      "---  ------             --------------   -----              \n",
      " 0   id                 215622 non-null  object             \n",
      " 1   date               215622 non-null  datetime64[ns, UTC]\n",
      " 2   user               215622 non-null  object             \n",
      " 3   content            215622 non-null  object             \n",
      " 4   in_reply_to_id     207130 non-null  object             \n",
      " 5   in_reply_to_user   206356 non-null  object             \n",
      " 6   conversation_id    215622 non-null  object             \n",
      " 7   conversation_user  215622 non-null  object             \n",
      " 8   reply_count        215622 non-null  int64              \n",
      " 9   retweet_count      215622 non-null  int64              \n",
      " 10  like_count         215622 non-null  int64              \n",
      " 11  quote_count        215622 non-null  int64              \n",
      " 12  view_count         89273 non-null   float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(4), object(7)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"../data/processed/sp_elected_stdep_tweets.csv\"\n",
    "# raw_df = pd.read_csv(file_path, on_bad_lines=\"skip\", sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "file_name = \"sp_elected_feddep_tweets\"\n",
    "file_format = \"parquet\"\n",
    "file_path = f\"../data/processed/{file_name}.{file_format}\"\n",
    "raw_df = pd.read_parquet(file_path)\n",
    "\n",
    "print(f'{raw_df.shape=}')\n",
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando c√≥pia antes de aplicar os filtros\n",
    "df = raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78226, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrando somente os tweets do per√≠odo desejado\n",
    "local_tz = pytz.timezone(\"America/Sao_Paulo\")\n",
    "since = datetime(year=2022, month=9, day=1, tzinfo=local_tz)\n",
    "until = datetime(year=2022, month=11, day=1, tzinfo=local_tz)\n",
    "\n",
    "df = df[\n",
    "    (df['date'] >= since ) &\n",
    "    (df['date'] <= until )\n",
    "]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78193, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo tweets com informa√ß√£o faltando de reply\n",
    "# Se 'user' √© diferente de 'conversation_user', ent√£o o tweet deveria ter tamb√©m 'in_reply_to_user'\n",
    "# Se n√£o tiver, √© por que o tweet respondido foi apagado, ou houve algum erro durante o scraping\n",
    "df = df[\n",
    "    ~((df['in_reply_to_user'].isnull()) &\n",
    "    (df['user'] != df['conversation_user']))\n",
    "]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df['conversation_user'] mais comuns: \n",
      "samiabomfim        0.504163\n",
      "rsallesmma         0.197076\n",
      "luizaerundina      0.107554\n",
      "marcofeliciano     0.085992\n",
      "pauloteixeira13    0.072027\n",
      "Name: conversation_user, dtype: float64\n",
      "\n",
      "df['user'] mais comuns: \n",
      "samiabomfim        0.010500\n",
      "rosangelamorosp    0.008505\n",
      "julianapt          0.005064\n",
      "luizaerundina      0.003658\n",
      "felipebecari       0.003415\n",
      "Name: user, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avaliando a distribui√ß√£o dos tweets entre os candidatos\n",
    "print(f\"df['conversation_user'] mais comuns: \\n{(df['conversation_user'].value_counts(normalize=True)[:5])}\\n\")\n",
    "print(f\"df['user'] mais comuns: \\n{(df['user'].value_counts(normalize=True)[:5])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "OFFENSE_MODELS = {\n",
    "    \"rc_bert_base\": \"ruanchaves/bert-base-portuguese-cased-hatebr\",\n",
    "    \"rc_mdeberta_base\": \"ruanchaves/mdeberta-v3-base-hatebr\",\n",
    "    \"cl_distilbert_base\": \"citizenlab/distilbert-base-multilingual-cased-toxicity\",\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df.content.str.len().sort_values().index\n",
    "tweets = df.reindex(indexes)\n",
    "tweets = tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = \"content\"\n",
    "batch_size = 32\n",
    "num_batches = len(tweets) // batch_size + 1\n",
    "results = {}\n",
    "\n",
    "def classify(model_name, tweets, col_name=\"content\", batch_size=32):\n",
    "    num_batches = len(tweets) // batch_size + 1\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device.type == \"cuda\":\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_name, device=0)\n",
    "    else:\n",
    "        classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
    "    \n",
    "    results = []\n",
    "    for i in tqdm(range(num_batches)):\n",
    "       batch_start = i * batch_size\n",
    "       batch_end = min((i + 1) * batch_size, len(tweets))\n",
    "       batch_texts = tweets[col_name][batch_start:batch_end].tolist()\n",
    "       batch_results = classifier(batch_texts)\n",
    "       results += batch_results\n",
    "    return results\n",
    "\n",
    "# for model_key in OFFENSE_MODELS.keys():\n",
    "#     results[model_key] = classify(OFFENSE_MODELS[model_key], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|‚ñå                                                                                                                               | 10/2444 [00:03<08:21,  4.85it/s]/home/paim/projects/projeto-tera/venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2444/2444 [11:44<00:00,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 26s, sys: 1min 20s, total: 11min 46s\n",
      "Wall time: 11min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_key = 'rc_bert_base'\n",
    "results[model_key] = classify(OFFENSE_MODELS[model_key], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2444/2444 [21:38<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 3s, sys: 2min 38s, total: 21min 42s\n",
      "Wall time: 21min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_key = 'rc_mdeberta_base'\n",
    "results[model_key] = classify(OFFENSE_MODELS[model_key], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|‚ñé                                                                              | 10/2444 [00:01<05:29,  7.39it/s]/home/paim/projects/projeto-tera/venv/lib/python3.8/site-packages/transformers/pipelines/base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2444/2444 [07:01<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 15s, sys: 49.6 s, total: 7min 4s\n",
      "Wall time: 7min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_key = 'cl_distilbert_base'\n",
    "results[model_key] = classify(OFFENSE_MODELS[model_key], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rc_bert_base\n",
      "rc_mdeberta_base\n",
      "cl_distilbert_base\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 78193 entries, 220 to 215619\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   id                        78193 non-null  object             \n",
      " 1   date                      78193 non-null  datetime64[ns, UTC]\n",
      " 2   user                      78193 non-null  object             \n",
      " 3   content                   78193 non-null  object             \n",
      " 4   in_reply_to_id            75049 non-null  object             \n",
      " 5   in_reply_to_user          74540 non-null  object             \n",
      " 6   conversation_id           78193 non-null  object             \n",
      " 7   conversation_user         78193 non-null  object             \n",
      " 8   reply_count               78193 non-null  int64              \n",
      " 9   retweet_count             78193 non-null  int64              \n",
      " 10  like_count                78193 non-null  int64              \n",
      " 11  quote_count               78193 non-null  int64              \n",
      " 12  view_count                0 non-null      float64            \n",
      " 13  rc_bert_base_label        78193 non-null  bool               \n",
      " 14  rc_bert_base_score        78193 non-null  float64            \n",
      " 15  rc_mdeberta_base_label    78193 non-null  bool               \n",
      " 16  rc_mdeberta_base_score    78193 non-null  float64            \n",
      " 17  cl_distilbert_base_label  78193 non-null  object             \n",
      " 18  cl_distilbert_base_score  78193 non-null  float64            \n",
      "dtypes: bool(2), datetime64[ns, UTC](1), float64(4), int64(4), object(8)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# for key in OFFENSE_MODELS.keys():\n",
    "for key in results.keys():\n",
    "    print(key)\n",
    "    df[f'{key}_label'] = [result[\"label\"] for result in results[key]]\n",
    "    df[f'{key}_score'] = [result[\"score\"] for result in results[key]]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_toxic    74638\n",
       "toxic         3555\n",
       "Name: cl_distilbert_base_label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cl_distilbert_base_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo labels do distilbert para booleano\n",
    "def get_distilbert_label(label):\n",
    "    if label == \"toxic\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "df['cl_distilbert_base_label'] = df.cl_distilbert_base_label.apply(get_distilbert_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39119\n",
       "1    20390\n",
       "2    16737\n",
       "3     1947\n",
       "Name: label_sum, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_offense_label_sum(row):\n",
    "    count = 0\n",
    "    if row['rc_bert_base_label'] == True:\n",
    "        count += 1\n",
    "    if row['rc_mdeberta_base_label'] == True:\n",
    "        count += 1\n",
    "    if row['cl_distilbert_base_label'] == True:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "df['label_sum'] = df.apply(get_offense_label_sum, axis=1)\n",
    "df['label_sum'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rc_bert_base_label  rc_mdeberta_base_label  cl_distilbert_base_label\n",
       "False               False                   False                       39119\n",
       "                    True                    False                       16143\n",
       "True                True                    False                       16128\n",
       "                    False                   False                        3248\n",
       "                    True                    True                         1947\n",
       "False               False                   True                          999\n",
       "                    True                    True                          442\n",
       "True                False                   True                          167\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['content', 'rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].value_counts()\n",
    "df[['rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rc_bert_base_label</th>\n",
       "      <th>rc_mdeberta_base_label</th>\n",
       "      <th>cl_distilbert_base_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78193</td>\n",
       "      <td>78193</td>\n",
       "      <td>78193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>56703</td>\n",
       "      <td>43533</td>\n",
       "      <td>74638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rc_bert_base_label rc_mdeberta_base_label cl_distilbert_base_label\n",
       "count               78193                  78193                    78193\n",
       "unique                  2                      2                        2\n",
       "top                 False                  False                    False\n",
       "freq                56703                  43533                    74638"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>rc_bert_base_label</th>\n",
       "      <th>rc_mdeberta_base_label</th>\n",
       "      <th>cl_distilbert_base_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>VEJA COMO A CORRUP√á√ÉO PETISTA DESTRUIU A SA√öDE E A EDUCA√á√ÉO! https://t.co/BKpepJjLGV</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>Chegamos pra plen√°ria de arrancada da vit√≥ria, com @LulaOficial presidente e @Haddad_Fernando governador ‚≠êÔ∏èüö© https://t.co/1XzCPKHXM3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13742</th>\n",
       "      <td>@luizaerundina Tu e mentirosa</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>@luizaerundina Bem esculachado e Bolsonaro ser√° ex presidente sim, em 2027</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14325</th>\n",
       "      <td>@luizaerundina https://t.co/83MUXC2LDv</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209671</th>\n",
       "      <td>@samiabomfim Voc√™ ficou estarrecida com a igreja do Chile quando pegou fogo? Ou √© por que um institudo t√™m mais facilidade de extorquir dinheiro do or√ßamento? que √© diferente de pedir (dismo). TODO INSTRUMENTO DE DEPREDA√á√ÉO DA RENDA DO TRABALHADOR √â O QUE VOC√ä DEFENDE. Vai um boleto a√≠?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209674</th>\n",
       "      <td>@samiabomfim ETA pessoa ignorante .</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209675</th>\n",
       "      <td>@samiabomfim Fake</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209676</th>\n",
       "      <td>@samiabomfim O direito j√° foi evento de golpe militar https://t.co/OZKAiSXBp8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209689</th>\n",
       "      <td>@samiabomfim Amanh√£, 02/09, completa quatro anos dessa trag√©dia no Rio.üëá\\n\\nhttps://t.co/eqTiEeWCqi</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1947 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                content  \\\n",
       "667                                                                                                                                                                                                                VEJA COMO A CORRUP√á√ÉO PETISTA DESTRUIU A SA√öDE E A EDUCA√á√ÉO! https://t.co/BKpepJjLGV   \n",
       "4329                                                                                                                                                               Chegamos pra plen√°ria de arrancada da vit√≥ria, com @LulaOficial presidente e @Haddad_Fernando governador ‚≠êÔ∏èüö© https://t.co/1XzCPKHXM3   \n",
       "13742                                                                                                                                                                                                                                                                     @luizaerundina Tu e mentirosa   \n",
       "14182                                                                                                                                                                                                                        @luizaerundina Bem esculachado e Bolsonaro ser√° ex presidente sim, em 2027   \n",
       "14325                                                                                                                                                                                                                                                            @luizaerundina https://t.co/83MUXC2LDv   \n",
       "...                                                                                                                                                                                                                                                                                                 ...   \n",
       "209671  @samiabomfim Voc√™ ficou estarrecida com a igreja do Chile quando pegou fogo? Ou √© por que um institudo t√™m mais facilidade de extorquir dinheiro do or√ßamento? que √© diferente de pedir (dismo). TODO INSTRUMENTO DE DEPREDA√á√ÉO DA RENDA DO TRABALHADOR √â O QUE VOC√ä DEFENDE. Vai um boleto a√≠?   \n",
       "209674                                                                                                                                                                                                                                                              @samiabomfim ETA pessoa ignorante .   \n",
       "209675                                                                                                                                                                                                                                                                                @samiabomfim Fake   \n",
       "209676                                                                                                                                                                                                                    @samiabomfim O direito j√° foi evento de golpe militar https://t.co/OZKAiSXBp8   \n",
       "209689                                                                                                                                                                                              @samiabomfim Amanh√£, 02/09, completa quatro anos dessa trag√©dia no Rio.üëá\\n\\nhttps://t.co/eqTiEeWCqi   \n",
       "\n",
       "        rc_bert_base_label  rc_mdeberta_base_label  cl_distilbert_base_label  \n",
       "667                   True                    True                      True  \n",
       "4329                  True                    True                      True  \n",
       "13742                 True                    True                      True  \n",
       "14182                 True                    True                      True  \n",
       "14325                 True                    True                      True  \n",
       "...                    ...                     ...                       ...  \n",
       "209671                True                    True                      True  \n",
       "209674                True                    True                      True  \n",
       "209675                True                    True                      True  \n",
       "209676                True                    True                      True  \n",
       "209689                True                    True                      True  \n",
       "\n",
       "[1947 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label_sum\"] == 3][['content', 'rc_bert_base_label', 'rc_mdeberta_base_label', 'cl_distilbert_base_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/processed/sp_elected_feddep_tweets-hf_classified.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = \"../data/processed/\"\n",
    "output_suffix = \"hf_classified\"\n",
    "output_file = f\"{output_path}{file_name}-hf_classified.{file_format}\"\n",
    "\n",
    "print(output_file)\n",
    "\n",
    "# Para salvar os dados, descomente as linhas abaixo\n",
    "if file_format == 'csv':\n",
    "    df.to_csv(output_file, sep=\";\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "if file_format == 'parquet':\n",
    "    df.to_parquet(output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step classification\n",
    "\n",
    "C√≥digo experimental abaixo, ainda precisa de mais testes e refinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Classification head function\n",
    "def get_class(logit):\n",
    "    scores = softmax(logit)\n",
    "    label = config.id2label[np.argmax(scores)]\n",
    "    # print(f\"get_class(): {logit=}, {scores=}, {label=}\")\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_gpu(batch):\n",
    "    model_input = tokenizer(\n",
    "        *(list(batch[\"rawContent\"]),), padding=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**model_input)\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "    return logits\n",
    "\n",
    "\n",
    "def process_batch_cpu(batch):\n",
    "    model_input = tokenizer(\n",
    "        *(list(batch[\"rawContent\"]),), padding=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**model_input)\n",
    "        logits = outputs.logits.detach().numpy()\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\":  # GPU\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "    process_batch = process_batch_gpu\n",
    "\n",
    "else:  # CPU\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    process_batch = process_batch_cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "logits_list = []\n",
    "\n",
    "# for i in tqdm(range(0, len(df), BATCH_SIZE)):\n",
    "for i in range(0, len(df), BATCH_SIZE):\n",
    "    if i + BATCH_SIZE < len(df):\n",
    "        batch = df.iloc[i : i + BATCH_SIZE].copy()\n",
    "    else:\n",
    "        batch = df.iloc[i : len(df)].copy()\n",
    "\n",
    "    logits = process_batch(batch)\n",
    "    logits_list.append(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.concatenate(logits_list)\n",
    "logits.shape\n",
    "\n",
    "classes = []\n",
    "for logit in logits:\n",
    "    classes.append(get_class(logit))\n",
    "\n",
    "df[\"BertL-offense\"] = classes\n",
    "df.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_df = df[df[\"BertL-offense\"] == True]\n",
    "print(offensive_df.shape)\n",
    "offensive_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_df[\"rawContent\"].values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
